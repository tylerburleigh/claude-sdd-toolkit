# High-Leverage Improvements: Adopting BMAD's Approach

## Executive Summary

Based on analysis of BMAD's document-project system and your current code-doc implementation, here are the **highest leverage improvements** ranked by impact vs. effort:

1. **ðŸ¥‡ Multi-File Output with index.md** (High Impact, Medium Effort)
2. **ðŸ¥ˆ Content Variable System** (High Impact, Medium-High Effort)  
3. **ðŸ¥‰ Project Type Awareness** (Medium Impact, Low Effort)
4. **4ï¸âƒ£ Resumability** (Medium Impact, Medium Effort)
5. **5ï¸âƒ£ Write-as-You-Go Pattern** (Low-Medium Impact, Medium Effort)

---

## ðŸ¥‡ Priority 1: Multi-File Output with index.md

### Current State
- Single `documentation.json` file (can be very large)
- Single `documentation.md` file (can be very large)
- No navigation structure
- Hard to load selectively

### BMAD Approach
- `index.md` as master entry point
- Multiple focused files: `architecture.md`, `components.md`, `api.md`, etc.
- Clear navigation and descriptions
- Enables intelligent loading

### Why Highest Leverage

**Impact:**
- âœ… Enables INDEX_GUIDED loading (see Priority 2)
- âœ… Prevents context exhaustion (load only what's needed)
- âœ… Better organization for AI assistants
- âœ… Easier to navigate and maintain
- âœ… Backward compatible (can still generate single files)

**Effort:** Medium (2-3 days)
- Modify formatter to generate multiple files
- Create index.md generator
- Add file splitting logic

### Implementation Plan

#### Step 1: Add Multi-File Output Option

**Modify `code_doc/cli.py`:**
```python
# Add flag
parser.add_argument(
    '--multi-file',
    action='store_true',
    help='Generate multi-file documentation with index.md (default: single file)'
)
```

**Modify `code_doc/formatter.py`:**
```python
class MarkdownGenerator:
    def generate_multi_file(
        self, 
        analysis: Dict[str, Any], 
        statistics: Dict[str, Any],
        output_dir: Path
    ) -> Dict[str, Path]:
        """
        Generate multi-file documentation structure.
        
        Returns:
            Dict mapping file names to Path objects
        """
        files = {}
        
        # 1. Generate index.md (master entry point)
        files['index.md'] = self._generate_index(analysis, statistics, output_dir)
        
        # 2. Generate focused files
        files['statistics.md'] = self._generate_statistics_file(statistics)
        files['classes.md'] = self._generate_classes_file(analysis['classes'])
        files['functions.md'] = self._generate_functions_file(analysis['functions'])
        files['dependencies.md'] = self._generate_dependencies_file(analysis['dependencies'])
        
        # 3. Language-specific files (if multi-language)
        if len(statistics.get('by_language', {})) > 1:
            files['languages.md'] = self._generate_languages_file(statistics)
        
        # 4. Cross-references file (if available)
        if self._has_cross_references(analysis):
            files['cross-references.md'] = self._generate_cross_references_file(analysis)
        
        return files
    
    def _generate_index(
        self, 
        analysis: Dict[str, Any], 
        statistics: Dict[str, Any],
        output_dir: Path
    ) -> Path:
        """Generate master index.md file."""
        lines = [
            f"# {self.project_name} Documentation",
            "",
            f"**Version:** {self.version}",
            f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "## Quick Reference",
            "",
            f"- **Total Files:** {statistics.get('total_files', 0)}",
            f"- **Total Classes:** {statistics.get('total_classes', 0)}",
            f"- **Total Functions:** {statistics.get('total_functions', 0)}",
            f"- **Languages:** {', '.join(statistics.get('by_language', {}).keys())}",
            "",
            "## Documentation Files",
            "",
            "- [Statistics](./statistics.md) - Project statistics and metrics",
            "- [Classes](./classes.md) - All classes with details",
            "- [Functions](./functions.md) - All functions with signatures",
            "- [Dependencies](./dependencies.md) - Dependency graph",
            "",
            "## For AI-Assisted Development",
            "",
            "This documentation was generated to enable AI agents to understand and extend this codebase.",
            "",
            "### When Planning New Features:",
            "",
            "**Understanding existing code:**",
            "â†’ Reference: `classes.md`, `functions.md`",
            "",
            "**Finding dependencies:**",
            "â†’ Reference: `dependencies.md`",
            "",
            "**Understanding relationships:**",
            "â†’ Reference: `cross-references.md` (if available)",
            "",
            "---",
            "",
            f"_Generated by code-doc skill_"
        ]
        
        index_path = output_dir / "index.md"
        index_path.write_text('\n'.join(lines))
        return index_path
```

#### Step 2: Update Generator to Support Multi-File

**Modify `code_doc/generator.py`:**
```python
def save_markdown(
    self,
    output_path: Path,
    analysis: Dict[str, Any],
    statistics: Dict[str, Any],
    multi_file: bool = False,
    verbose: bool = False
):
    """Generate and save Markdown documentation."""
    if multi_file:
        # Generate multi-file structure
        output_dir = output_path.parent
        files = self.md_generator.generate_multi_file(
            analysis, statistics, output_dir
        )
        
        if verbose:
            print(f"âœ… Generated {len(files)} documentation files:")
            for name, path in files.items():
                print(f"   - {name}")
    else:
        # Single file (existing behavior)
        markdown = self.md_generator.generate(analysis, statistics)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(markdown)
        if verbose:
            print(f"âœ… Markdown: {output_path}")
```

#### Step 3: Keep JSON as Single File (for doc-query)

The JSON file should remain single-file for doc-query compatibility, but add a reference in index.md:

```markdown
## Machine-Readable Documentation

- [documentation.json](./documentation.json) - Complete structured data (for doc-query)
```

### Benefits

1. **Enables INDEX_GUIDED loading** (see Priority 2)
2. **Reduces context size** - Load only relevant files
3. **Better organization** - Each file has a clear purpose
4. **Backward compatible** - Default to single-file, opt-in to multi-file
5. **AI-friendly** - Clear structure for AI assistants

---

## ðŸ¥ˆ Priority 2: Content Variable System

### Current State
- Manual file path resolution in `doc_helper.py`
- Workflows must manually check for docs
- No automatic discovery/loading
- No standardized content variables

### BMAD Approach
- `discover_inputs` protocol automatically loads files
- Content variables like `{document_project_content}`
- INDEX_GUIDED strategy intelligently loads relevant docs
- Transparent reporting of what was loaded

### Why High Leverage

**Impact:**
- âœ… Automatic context loading for workflows
- âœ… No manual file management needed
- âœ… Consistent interface across workflows
- âœ… Intelligent loading prevents context exhaustion
- âœ… Makes docs immediately accessible to AI assistants

**Effort:** Medium-High (3-5 days)
- Create discovery protocol/task
- Implement INDEX_GUIDED loading
- Integrate with existing workflows
- Add content variable system

### Implementation Plan

#### Step 1: Create Discovery Protocol

**New file: `src/claude_skills/claude_skills/common/doc_discovery.py`:**

```python
"""
Documentation Discovery Protocol

Automatically discovers and loads code-doc documentation based on patterns.
Similar to BMAD's discover_inputs protocol.
"""

from pathlib import Path
from typing import Dict, List, Optional, Any
import json


class DocumentationDiscovery:
    """Discovers and loads code-doc documentation."""
    
    LOAD_STRATEGIES = {
        'FULL_LOAD': 'load_all_files',
        'INDEX_GUIDED': 'load_index_guided',
        'SELECTIVE_LOAD': 'load_selective'
    }
    
    def __init__(self, output_folder: Optional[Path] = None):
        self.output_folder = output_folder or Path.cwd() / "docs"
        self.loaded_content: Dict[str, str] = {}
    
    def discover(
        self, 
        patterns: Dict[str, Dict[str, Any]]
    ) -> Dict[str, str]:
        """
        Discover and load documentation based on patterns.
        
        Args:
            patterns: Dict mapping variable names to pattern configs:
                {
                    'code_doc': {
                        'sharded': '{output_folder}/index.md',
                        'load_strategy': 'INDEX_GUIDED'
                    }
                }
        
        Returns:
            Dict mapping variable names to loaded content
        """
        for var_name, config in patterns.items():
            strategy = config.get('load_strategy', 'FULL_LOAD')
            
            if strategy == 'INDEX_GUIDED':
                content = self._load_index_guided(config)
            elif strategy == 'FULL_LOAD':
                content = self._load_full(config)
            elif strategy == 'SELECTIVE_LOAD':
                content = self._load_selective(config)
            else:
                content = ""
            
            self.loaded_content[var_name] = content
        
        return self.loaded_content
    
    def _load_index_guided(self, config: Dict[str, Any]) -> str:
        """
        Load documentation using INDEX_GUIDED strategy.
        
        1. Load index.md
        2. Parse structure
        3. Identify relevant files
        4. Load those files
        """
        sharded_pattern = config.get('sharded', '')
        if not sharded_pattern:
            return ""
        
        # Resolve pattern (handle {output_folder} substitution)
        index_path = Path(str(sharded_pattern).format(
            output_folder=self.output_folder
        ))
        
        if not index_path.exists():
            return ""
        
        # Load index.md
        index_content = index_path.read_text()
        
        # Parse index to find linked files
        linked_files = self._parse_index_links(index_path, index_content)
        
        # Load linked files
        loaded_files = [index_content]  # Start with index
        
        for file_path in linked_files:
            if file_path.exists():
                loaded_files.append(f"\n\n---\n\n# {file_path.name}\n\n")
                loaded_files.append(file_path.read_text())
        
        return "\n".join(loaded_files)
    
    def _parse_index_links(
        self, 
        index_path: Path, 
        index_content: str
    ) -> List[Path]:
        """
        Parse index.md to find linked documentation files.
        
        Looks for markdown links like [Statistics](./statistics.md)
        """
        import re
        
        links = []
        base_dir = index_path.parent
        
        # Find markdown links
        link_pattern = r'\[([^\]]+)\]\(([^)]+)\)'
        matches = re.findall(link_pattern, index_content)
        
        for title, link in matches:
            # Resolve relative paths
            if link.startswith('./'):
                link = link[2:]
            
            file_path = base_dir / link
            if file_path.exists() and file_path.suffix == '.md':
                links.append(file_path)
        
        return links
    
    def _load_full(self, config: Dict[str, Any]) -> str:
        """Load all files matching pattern."""
        # Implementation similar to INDEX_GUIDED but loads all .md files
        pattern = config.get('sharded', '')
        if not pattern:
            return ""
        
        base_dir = Path(str(pattern).format(
            output_folder=self.output_folder
        )).parent
        
        if not base_dir.exists():
            return ""
        
        # Load all .md files
        md_files = sorted(base_dir.glob("*.md"))
        contents = []
        
        for md_file in md_files:
            contents.append(md_file.read_text())
        
        return "\n\n---\n\n".join(contents)
    
    def _load_selective(self, config: Dict[str, Any]) -> str:
        """Load specific file based on template variables."""
        # Implementation for selective loading
        # Similar to BMAD's SELECTIVE_LOAD strategy
        pass
```

#### Step 2: Integrate with Workflows

**Update `doc_helper.py`:**

```python
from .doc_discovery import DocumentationDiscovery

def get_code_doc_content(
    output_folder: Optional[Path] = None,
    load_strategy: str = "INDEX_GUIDED"
) -> Optional[str]:
    """
    Get code-doc content using discovery protocol.
    
    Args:
        output_folder: Documentation output folder
        load_strategy: 'INDEX_GUIDED', 'FULL_LOAD', or 'SELECTIVE_LOAD'
    
    Returns:
        Content string or None if not found
    """
    discovery = DocumentationDiscovery(output_folder)
    
    patterns = {
        'code_doc': {
            'sharded': '{output_folder}/index.md',
            'load_strategy': load_strategy
        }
    }
    
    result = discovery.discover(patterns)
    return result.get('code_doc')
```

#### Step 3: Add to Agent Instructions

**Update `agents/code-doc.md`:**

```markdown
## Content Variables

After generating documentation, it's available as:
- `{code_doc_content}` - Full documentation content (when using discovery)
- `{code_doc_json_path}` - Path to documentation.json (for doc-query)
```

### Benefits

1. **Automatic loading** - No manual file reading
2. **Intelligent selection** - INDEX_GUIDED loads only relevant docs
3. **Consistent interface** - Same variable name across workflows
4. **Context management** - Prevents loading unnecessary content
5. **Transparency** - Reports what was loaded

---

## ðŸ¥‰ Priority 3: Project Type Awareness

### Current State
- Generic scanning approach
- Framework detection (FastAPI, Django, etc.)
- No project type-specific strategies

### BMAD Approach
- 12 project types (web, mobile, backend, CLI, etc.)
- Type-specific scanning requirements
- Conditional scanning based on type

### Why Medium Leverage

**Impact:**
- âœ… More efficient scanning (skip irrelevant areas)
- âœ… Better documentation organization
- âœ… Type-specific insights
- âœ… Faster generation for large projects

**Effort:** Low (1-2 days)
- Add project type detection
- Create type-specific formatters
- Add conditional scanning

### Implementation Plan

**New file: `src/claude_skills/claude_skills/code_doc/project_types.py`:**

```python
"""
Project Type Detection and Configuration
"""

from typing import Dict, List, Optional
from pathlib import Path


PROJECT_TYPES = {
    'web': {
        'detection_patterns': [
            'package.json', 'tsconfig.json', 'vite.config.*',
            'next.config.*', 'nuxt.config.*'
        ],
        'critical_directories': ['src/', 'app/', 'pages/', 'components/'],
        'requires': ['ui_components', 'api_scan', 'state_management']
    },
    'backend': {
        'detection_patterns': [
            'requirements.txt', 'go.mod', 'pom.xml', 'build.gradle'
        ],
        'critical_directories': ['src/', 'api/', 'services/', 'models/'],
        'requires': ['api_scan', 'data_models']
    },
    'cli': {
        'detection_patterns': [
            'setup.py', 'pyproject.toml', '*.gemspec'
        ],
        'critical_directories': ['src/', 'cmd/', 'cli/'],
        'requires': []
    },
    # ... more types
}


def detect_project_type(project_root: Path) -> Optional[str]:
    """Detect project type based on file patterns."""
    for type_name, config in PROJECT_TYPES.items():
        patterns = config['detection_patterns']
        for pattern in patterns:
            if list(project_root.glob(pattern)):
                return type_name
    return None


def get_type_specific_config(project_type: str) -> Dict:
    """Get configuration for a project type."""
    return PROJECT_TYPES.get(project_type, {})
```

**Modify `code_doc/generator.py`:**

```python
from .project_types import detect_project_type, get_type_specific_config

def generate(self, verbose: bool = False) -> Dict[str, Any]:
    # Detect project type
    project_type = detect_project_type(self.project_dir)
    
    if project_type and verbose:
        print(f"ðŸ“‹ Detected project type: {project_type}")
    
    # Get type-specific config
    type_config = get_type_specific_config(project_type) if project_type else {}
    
    # Adjust scanning based on type
    # ... existing parsing logic ...
```

### Benefits

1. **Efficient scanning** - Focus on relevant areas
2. **Better organization** - Type-specific documentation structure
3. **Faster generation** - Skip irrelevant files
4. **Type-specific insights** - Better recommendations

---

## 4ï¸âƒ£ Priority 4: Resumability

### Current State
- No resumability
- Must regenerate entire documentation
- No progress tracking

### BMAD Approach
- State file (`project-scan-report.json`)
- Resume from interruption
- Progress tracking

### Why Medium Leverage

**Impact:**
- âœ… Handle large codebases better
- âœ… Recover from interruptions
- âœ… Faster incremental updates

**Effort:** Medium (2-3 days)
- Add state tracking
- Implement resume logic
- Add progress reporting

### Implementation Plan

**Add to `code_doc/generator.py`:**

```python
import json
from datetime import datetime

class DocumentationGenerator:
    def __init__(self, ...):
        # ... existing init ...
        self.state_file = output_dir / "code-doc-state.json"
    
    def generate(self, resume: bool = True, verbose: bool = False):
        # Check for existing state
        if resume and self.state_file.exists():
            state = self._load_state()
            if self._should_resume(state):
                return self._resume_generation(state, verbose)
        
        # Start fresh generation
        return self._fresh_generation(verbose)
    
    def _save_state(self, step: str, progress: Dict):
        """Save generation state."""
        state = {
            'version': '1.0.0',
            'last_updated': datetime.now().isoformat(),
            'current_step': step,
            'progress': progress,
            'completed_modules': progress.get('completed_modules', [])
        }
        self.state_file.write_text(json.dumps(state, indent=2))
    
    def _load_state(self) -> Dict:
        """Load generation state."""
        return json.loads(self.state_file.read_text())
    
    def _should_resume(self, state: Dict) -> bool:
        """Determine if should resume from state."""
        # Check age (e.g., < 24 hours)
        last_updated = datetime.fromisoformat(state['last_updated'])
        age = datetime.now() - last_updated
        return age.total_seconds() < 24 * 3600
```

### Benefits

1. **Handle interruptions** - Resume from where left off
2. **Incremental updates** - Only regenerate changed parts
3. **Large codebases** - Better handling of big projects

---

## 5ï¸âƒ£ Priority 5: Write-as-You-Go Pattern

### Current State
- Accumulates all data in memory
- Writes at end
- Risk of context exhaustion

### BMAD Approach
- Write files immediately
- Purge detailed findings after writing
- Keep only summaries in memory

### Why Lower Priority

**Impact:**
- âœ… Prevents context exhaustion
- âœ… Better for very large projects
- âš ï¸ Less critical if Priority 1-2 implemented

**Effort:** Medium (2-3 days)
- Refactor to write incrementally
- Add memory management

### Implementation Plan

**Modify `code_doc/generator.py`:**

```python
def generate(self, verbose: bool = False):
    # Process modules one at a time
    for module in modules:
        # Parse module
        parsed = self._parse_module(module)
        
        # Write immediately (if multi-file mode)
        if self.multi_file:
            self._write_module_doc(parsed)
        
        # Purge detailed data, keep summary
        summary = self._create_summary(parsed)
        # ... continue with summary only ...
```

---

## Implementation Roadmap

### Phase 1: Foundation (Week 1)
1. âœ… **Priority 1: Multi-File Output** (2-3 days)
   - Implement multi-file generation
   - Create index.md generator
   - Add `--multi-file` flag
   - Test with sample projects

### Phase 2: Integration (Week 2)
2. âœ… **Priority 2: Content Variable System** (3-5 days)
   - Create `doc_discovery.py`
   - Implement INDEX_GUIDED loading
   - Integrate with `doc_helper.py`
   - Update agent instructions

### Phase 3: Optimization (Week 3)
3. âœ… **Priority 3: Project Type Awareness** (1-2 days)
   - Add project type detection
   - Create type-specific configs
   - Update generator

4. âœ… **Priority 4: Resumability** (2-3 days)
   - Add state tracking
   - Implement resume logic
   - Add progress reporting

### Phase 4: Polish (Week 4)
5. âœ… **Priority 5: Write-as-You-Go** (2-3 days)
   - Refactor incremental writing
   - Add memory management
   - Test with large projects

---

## Quick Wins (Can Do Immediately)

### 1. Add index.md to Single-File Output

Even without multi-file, add a simple index.md:

```python
def _generate_simple_index(self, output_dir: Path, json_path: Path):
    """Generate simple index.md pointing to documentation.json."""
    index_content = f"""# Documentation Index

## Machine-Readable Documentation

- [documentation.json](./documentation.json) - Complete structured data

## Usage

Use `doc-query` skill to query this documentation:
```bash
doc-query "find all classes"
```

_Generated by code-doc skill_
"""
    (output_dir / "index.md").write_text(index_content)
```

### 2. Add "For AI-Assisted Development" Section

Add to existing Markdown output:

```python
def _ai_guidance_section(self) -> str:
    return """
## For AI-Assisted Development

This documentation was generated to enable AI agents to understand and extend this codebase.

### When Planning New Features:

**Understanding existing code:**
â†’ Reference: Classes and Functions sections above

**Finding dependencies:**
â†’ Reference: Dependencies section above

**Understanding relationships:**
â†’ Use `doc-query` skill for semantic search
"""
```

### 3. Improve doc_helper.py Integration

Add better discovery:

```python
def discover_code_doc(output_folder: Optional[Path] = None) -> Dict[str, Any]:
    """
    Discover code-doc documentation and return metadata.
    
    Returns:
        {
            'available': bool,
            'index_path': Path | None,
            'json_path': Path | None,
            'files': List[Path]
        }
    """
    output_folder = output_folder or Path.cwd() / "docs"
    
    result = {
        'available': False,
        'index_path': None,
        'json_path': None,
        'files': []
    }
    
    # Check for index.md
    index_path = output_folder / "index.md"
    if index_path.exists():
        result['index_path'] = index_path
        result['available'] = True
    
    # Check for documentation.json
    json_path = output_folder / "documentation.json"
    if json_path.exists():
        result['json_path'] = json_path
        result['available'] = True
    
    # List all .md files
    result['files'] = list(output_folder.glob("*.md"))
    
    return result
```

---

## Success Metrics

After implementing Priority 1-2:

1. **Context Size Reduction:** 50-70% reduction in tokens when loading docs
2. **Workflow Integration:** 100% of workflows can access docs via variables
3. **Developer Experience:** No manual file path management needed
4. **AI Assistant Usage:** Docs automatically available in workflows

---

## Conclusion

**Highest leverage improvements:**
1. **Multi-File Output** - Enables everything else
2. **Content Variable System** - Makes docs accessible automatically
3. **Project Type Awareness** - Optimizes scanning
4. **Resumability** - Handles large codebases
5. **Write-as-You-Go** - Prevents context exhaustion

**Recommended order:** Start with Priority 1 (multi-file), then Priority 2 (content variables). These two provide the most value and enable the others.
